---
title: Web性能优化简要总结
date: 2017-05-18 22:52:03
tags:
---

{% asset_img loading.jpg %}
基于HTTP协议的Web应用已经成为互联网的核心，优化Web应用性能、改善用户体验成为了非常重要的问题。
<!--more-->
# 性能指标
优化性能，首先要有衡量性能的指标，Chrome提供了十分科学高效的性能测量工具，Waterfall。
在Chrome的DevTool中，NetWork选项卡里就有所有请求的性能指标。（在打开DevTool后的请求才会被记录）
{% asset_img DevTool.png %}
上面的图是访问`baidu.com`的结果。
因为之前已经有过访问历史，所以需要做出两点改进，以模拟用户第一次访问时的场景。
首先，需要清除掉浏览器DNS缓存及本地DNS缓存。
DNS又叫做域名系统，也就是各个网站的网址。与ip地址相比，域名方便人们记忆和传播，可以说域名是ip地址的助记符。而机器并不能直接识别域名，所以需要通过DNS协议来查找域名对应的真实的ip地址。在每次尝试访问新的域名时，浏览器都会向网络服务提供商询问所要访问域名的ip地址，如果也没有找到，就会通过递归或迭代的方式向更上级的DNS服务器询问，直至找到结果。在找到结果后浏览器和操作系统会将这个结果缓存下来，在下次查询同样的域名时更快的返回结果。
然后，需要勾选Disable cache。浏览器同样会将访问过的静态资源缓(js/css/img...)存到本地，以便下一次打开该网站时更快的加载。
在做好准备工作时，我们可以选择最开始的一条请求，观察它的Waterfall数据。
{% asset_img WaterFall.png %}
在Google的开发者网站上，我们可以逐条找到这些条目的含义。
*Queueing：请求处于队列。当前有更高优先级的请求或者该域名已经有六个TCP连接时会出现。*
*Stalled：任何使请求处于队列的原因同样也会使请求阻塞。*
*DNS Lookup：浏览器正在解析域名到对应的ip地址。*
*Proxy negotiation: 浏览器正在与代理服务器协商。当使用了代理时，会出现该情况。*
*Request sent: 浏览器正在发送请求。*
*Service Worker Preparation： 浏览器正在启动Service Worker。*
*Request to Service Worker： 浏览器正在向Service Worker发送请求。*
*Waiting（TTFB）：浏览器正在等待响应的第一个字节。*
*Content Download：浏览器正在接收响应。*
有一部分字段在开发者网站上也没有标注，不过根据名字我们就可以了解它们的含义。
例如SSL代表SSL的握手阶段耗时。
下面我们对于每一个字段仔细探讨一下优化策略。
# 请求优化
我们将下列字段都视为一次请求的阶段。
* Queue & Stalled
* Proxy negotiation
* DNS Lookup
* Initial connection
* SSL
* Request sent
* Content Download
## Queue & Stalled
由开发者网站我们可以了解到，Queue & Stalled主要由两个原因，一个是此时有更高优先级的连接，另一个是浏览器对同一个域名最多会有六个TCP连接。
对于来自更高优先级连接的阻塞我们没有更好的办法，连接的优先级并不能手动来控制，例如VoIP（实时语音通话）的优先级势必会比打开一个网页要高很多。
### 域名发散
浏览器对于一个同一个域名下的资源最多有六个并行的TCP连接，这会节省服务器的内存，也会减少线路上的拥塞程度。但作为网站，希望尽可能的利用带宽，那就需要用到`domain sharing`域名发散。所谓发散，就是将网站的资源分散到多个域名，以避免浏览器的单域名并行限制。这就是大多数网站都会有单独的`static`静态资源域名。
## Proxy negotiation
当使用了如VPN、Socks5等类型的本地代理时，浏览器需要先与本地代理通信。尽管这并不是必要的步骤但使用代理可以带来很多安全方面的好处，例如隐藏自己的真实ip等。
## DNS Lookup
前面已经提及DNS的作用和机制。在浏览器向一个陌生的域名发起请求前，需要进行DNS Lookup，也就是DNS寻址。DNS寻址使用UDP 53号端口。在使用有线以太网时，UDP可靠性较高不易丢失数据包，而在移动端等弱网环境下，UDP数据包十分容易受到干扰而丢失或失效，继而需要重新查询，这导致DNS寻址花费时间较长。
### 域名收敛
所以在移动端条件下，经常应用域名收敛替代域名发散的策略。将资源域名收敛到一至两个，能够很大程度上减少需要DNS寻址的次数，不至于在寻址过程花费太多时间。
## Initial connection
这里的Initial connection指代与远端服务器建立TCP链接，包括SSL握手的步骤。TCP链接属于TCP/IP协议栈的传输层，是不能够变更的，但服务端仍然有优化的策略。
### BBR Congestion Control
拥塞控制是TCP协议中十分重要的部分，简单介绍一下TCP的拥塞控制。  
#### 拥塞控制
难以计数的路由节点和线路构成了庞大的网络链路，是网络通信的基础。网络链路上承载着纷错交叉的TCP连接，端到端通信的数据包就依赖于这些TCP连接。如果将网络链路比作高速公路网，那么一条条货运专线就是TCP连接，在货运专线上飞驰的货车就是一个个数据包。就像节假日热门的收费站会堵车排队，如果某条链路上的数据包太多（例如很多人用2M带宽下载电影），那么就会出现拥塞。假如服务端不知道中途出现了拥塞的情况，还在一直全速发送数据包，那就会进一步加剧拥塞，最后导致节点瘫痪。在TCP协议被设计时，这种情况就被考虑到并且处理的十分优雅。
#### TCP 慢启动
TCP协议使用了一种被称为“慢启动”的拥塞控制算法。在刚建立TCP连接时，发送数据的一方（一般是服务端）首先仅发送一个数据包，如果在正常时限内收到回执确认，则说明链路拥塞情况良好，下一轮会发送两个数据包，再下一轮八个，十六个、三十二个……如此指数上升。当出现丢包的情况时，说明出现拥塞，此时将发送的数据包数减半，然后每轮以一递增，直到再次出现拥塞情况，进入下一轮”慢启动“。
{% asset_img slow-start.jpg %}
现代的TCP拥塞控制还加入了”快恢复“的特性，但基于”慢启动”的TCP拥塞控制算法判定拥塞的标识始终是出现丢包。
#### BBR
BBR全称是Bottleneck Bandwidth and Round-trip propagation time，大意是瓶颈带宽和往返传播时间，是Google在2016年发表的新型TCP拥塞控制算法。BBR算法与现在的默认拥塞控制算法相比，不同的地方主要在于其可以更加充分的利用“延迟高、带宽大“的链路。BBR并不会在一出现丢包就判定线路拥塞，而是可以容忍一定的丢包率，从而在延迟稍高的链路上更加激进地利用带宽。在服务器和客户端之间网络状况较差的情况下（服务器在境外）效果格外明显。
在Linux Kernel 4.9下可以手动开启BBR算法。
```
# Linux 4.9 CentOS
echo 'net.core.default_qdisc=fq' | sudo tee -a /etc/sysctl.conf
echo 'net.ipv4.tcp_congestion_control=bbr' | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
```
## SSL
SSL全称是Secure Sockets Layer，是用于保护HTTP通信免受中间人攻击的主要方式。HTTP通信时以明文发送内容，这样使得浏览器发送的消息可以被位于途中的中间人偷窥甚至修改。SSL协议约定了一套端到端加密的中间层，以保障通信内容不会泄露给第三者。
在建立TCP连接后，发送HTTP报文前，客户端会首先进行SSL握手，握手过程包括双方协商好加密算法、加密所需要的随机数，以及验证服务端提供的证书等步骤。之后的HTTP通信就会首先经过约定好的加密方式进行加密，以确保消息不被泄露。
由于SSL握手及加密需要传输额外的消息以及进行加密解密运算，实际上SSL会拖慢加载时间。
### HTTP/2
当前主流的HTTP协议版本号为1.1，HTTP/2是下一代HTTP协议，其提供了很多新特性。HTTP/2要求必须启用SSL，HTTP/2的性能优化策略极大优于HTTP/1.1，足以弥补SSL带来的性能损耗。
#### 基于二进制
HTTP/2的通信内容基于二进制传输，而非HTTP/1.1的文本，二进制格式在体积、解析及扩展方面都要优于文本格式。
#### 消息头压缩
通信双方会维护一份索引表，用以压缩消息头。已经在表中的头可以直接以该头在表中的索引值代替，从而避免每次通信都需要携带头的冗余。同时在通信时双方还会对字符串进行霍夫曼编码来压缩字符串的大小。
#### 多路复用
请求被以frame为单位分割，多个请求的frame可以在同一条TCP上连续传输，而不是HTTP/1.1中的单条TCP连接上的请求必须串行传输。这有效提高了传输效率。
#### Server Push
在HTTP/2中，服务端不再是被动的接收请求然后响应请求，而是有能力主动将一些未来可能需要的资源推到浏览器端，在将来浏览器需要这些资源时便可以直接使用。
## Request sent
HTTP请求的体积也是影响性能的重要因素，除去必要的请求头以外，Cookie字段往往是最冗长的部分。只要在本网站域设置了Cookie值，无论有没有用到，浏览器都会在每次请求中携带完整的Cookie值，浪费宝贵的带宽，例如许多网站将记住的用户名或密码长期存储在Cookie中。
### 本地存储
利用本地存储将Cookie中不易变更的信息长期保存在浏览器端，可以简化冗长的Cookie字段，缓减带宽压力。尽管长度为数k的的Cookie在单次通信中并不会有很大的影响，但当有数百万个并发请求时，这些Cookie所占用的带宽就会十分显著了。
## Content Download
一般情况下*Content Download*的传输数据体积在所有阶段中时最大的。这就需要尽力精简需要下载的资源体积，及加快下载速度。
### Compress
对于文本类型的静态资源（如html/css/js），可以通过删去所有空白字符以及将函数名和调用精简为短字符串的方式，在不影响其执行的情况下很大程度上压缩资源文件的体积。
### Gzip
Gzip是一种非常通用的压缩算法，通过在服务端开启Gzip能够十分显著地减少文本资源的体积，从而极大节约带宽。
一个实际的例子是原本4.8M的bundle.js在开启了Compress及Gzip后，体积缩减为不足400k，本来需要接近半分钟的加载时间，压缩后减为3秒左右。
### CDN
CDN全称为Content Delivery NetWork，这种机制将静态资源分布在各个节点，在浏览器请求时选取最近的节点提供服务。例如位于境外的网站，也在国内部署了CDN节点，那么当国内的用户请求它的静态资源时，不必再远赴重洋建立链接，而是就近选择，获得更佳的体验。CDN同样也可以减轻主站负载，分担流量。
# 后端优化
在请求发送完毕，收到第一个响应的字节前的阶段为*Waiting（TTFB）*，这个阶段的耗时主要来自后端处理请求。
一般情况的后端处理请求耗时主要包括以下阶段
* CGI程序运行
* 与数据存储源交互
* 数据库优化
## CGI & FastCGI
CGI全称为Common Gateway Interface，意为通用网关接口。HTTP Server接收到来自客户端的请求时，不会直接处理这些请求，而是通过fork一个新的进程，让其他的程序（例如C++、Perl等）来处理。但fork进程的代价很高，所以现在通常使用FastCGI的方式，即在内存中常驻若干已经初始化完成的CGI程序，在请求到达时可以很快地处理并响应。（例如php-fpm）
## JIT
通常语言分为两类，编译型和解释型。编译型的语言（例如C++）在编写完成后需要编译成为机器码才能运行，但运行效率很高。

# 前端优化
## 解析优化
### big pipe
# 并发优化